#!/usr/bin/env python3
"""
í•œêµ­ì–´ ì—¬í–‰ ì±—ë´‡ ëª¨ë¸ í•™ìŠµ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
"""

import os
import subprocess
import sys
import time

def check_requirements():
    """í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸"""
    required_packages = [
        "transformers",
        "torch", 
        "peft",
        "datasets",
        "accelerate",
        "bitsandbytes"
    ]
    
    print("ğŸ“¦ í•„ìš”í•œ íŒ¨í‚¤ì§€ í™•ì¸ ì¤‘...")
    missing_packages = []
    
    for package in required_packages:
        try:
            __import__(package)
            print(f"âœ… {package} - ì„¤ì¹˜ë¨")
        except ImportError:
            print(f"âŒ {package} - ì„¤ì¹˜ í•„ìš”")
            missing_packages.append(package)
    
    if missing_packages:
        print(f"\nğŸ”§ ë‹¤ìŒ íŒ¨í‚¤ì§€ë“¤ì„ ì„¤ì¹˜í•´ì£¼ì„¸ìš”:")
        for package in missing_packages:
            print(f"pip install {package}")
        return False
    
    return True

def create_dataset():
    """ë°ì´í„°ì…‹ ìƒì„±"""
    print("\nğŸ“ ë°ì´í„°ì…‹ ìƒì„± ì¤‘...")
    try:
        subprocess.run([sys.executable, "create_dataset.py"], check=True)
        return True
    except subprocess.CalledProcessError:
        print("âŒ ë°ì´í„°ì…‹ ìƒì„± ì‹¤íŒ¨")
        return False

def run_training():
    """ëª¨ë¸ í•™ìŠµ ì‹¤í–‰"""
    print("\nğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    
    # í•™ìŠµ íŒŒë¼ë¯¸í„° ì„¤ì •
    training_config = {
        "model_id": "meta-llama/Meta-Llama-3-1B",
        "output_dir": "./lora-travel-bot",
        "num_epochs": 3,
        "batch_size": 2,
        "learning_rate": 2e-4
    }
    
    print(f"ğŸ“‹ í•™ìŠµ ì„¤ì •:")
    print(f"  - ëª¨ë¸: {training_config['model_id']}")
    print(f"  - ì¶œë ¥ ë””ë ‰í† ë¦¬: {training_config['output_dir']}")
    print(f"  - ì—í¬í¬: {training_config['num_epochs']}")
    print(f"  - ë°°ì¹˜ í¬ê¸°: {training_config['batch_size']}")
    print(f"  - í•™ìŠµë¥ : {training_config['learning_rate']}")
    
    try:
        # í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
        subprocess.run([sys.executable, "../llama3_finetune_lora.py"], check=True)
        return True
    except subprocess.CalledProcessError:
        print("âŒ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨")
        return False

def convert_to_ollama():
    """í•™ìŠµëœ ëª¨ë¸ì„ Ollama í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    print("\nğŸ”„ Ollama ëª¨ë¸ ë³€í™˜ ì¤‘...")
    
    try:
        # ëª¨ë¸ ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
        convert_script = """
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel
import os

# í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ
base_model = AutoModelForCausalLM.from_pretrained("meta-llama/Meta-Llama-3-1B")
model = PeftModel.from_pretrained(base_model, "./lora-travel-bot")
tokenizer = AutoTokenizer.from_pretrained("meta-llama/Meta-Llama-3-1B")

# í†µí•©ëœ ëª¨ë¸ ì €ì¥
model.save_pretrained("./travel-bot-model")
tokenizer.save_pretrained("./travel-bot-model")

print("âœ… ëª¨ë¸ ë³€í™˜ ì™„ë£Œ!")
"""
        
        with open("convert_model.py", "w", encoding="utf-8") as f:
            f.write(convert_script)
        
        subprocess.run([sys.executable, "convert_model.py"], check=True)
        return True
    except subprocess.CalledProcessError:
        print("âŒ ëª¨ë¸ ë³€í™˜ ì‹¤íŒ¨")
        return False

def create_ollama_modelfile():
    """Ollama Modelfile ìƒì„±"""
    print("\nğŸ“„ Ollama Modelfile ìƒì„± ì¤‘...")
    
    modelfile_content = """FROM ./travel-bot-model

TEMPLATE """{{ if .System }}<|system|>
{{ .System }}<|end|>
{{ end }}{{ if .Prompt }}<|user|>
{{ .Prompt }}<|end|>
{{ end }}<|assistant|>
{{ .Response }}<|end|>"""

PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER top_k 40
PARAMETER repeat_penalty 1.1
PARAMETER num_predict 200

SYSTEM """ë‹¹ì‹ ì€ í•œêµ­ ì—¬í–‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•œêµ­ì˜ ë‹¤ì–‘í•œ ë„ì‹œì™€ ì§€ì—­ì— ëŒ€í•œ ì—¬í–‰ ì •ë³´ë¥¼ ì œê³µí•˜ê³ , ê°œì¸í™”ëœ ì—¬í–‰ ì¼ì •ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”. í•­ìƒ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” í†¤ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”."""
"""
    
    with open("Modelfile", "w", encoding="utf-8") as f:
        f.write(modelfile_content)
    
    print("âœ… Modelfile ìƒì„± ì™„ë£Œ!")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ í•œêµ­ì–´ ì—¬í–‰ ì±—ë´‡ ëª¨ë¸ í•™ìŠµ")
    print("=" * 50)
    
    # 1. íŒ¨í‚¤ì§€ í™•ì¸
    if not check_requirements():
        print("\nâŒ í•„ìš”í•œ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ìœ„ì˜ ëª…ë ¹ì–´ë“¤ì„ ì‹¤í–‰í•œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        return
    
    # 2. ë°ì´í„°ì…‹ ìƒì„±
    if not create_dataset():
        print("\nâŒ ë°ì´í„°ì…‹ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return
    
    # 3. ëª¨ë¸ í•™ìŠµ
    if not run_training():
        print("\nâŒ ëª¨ë¸ í•™ìŠµì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return
    
    # 4. Ollama ëª¨ë¸ ë³€í™˜
    if not convert_to_ollama():
        print("\nâŒ ëª¨ë¸ ë³€í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return
    
    # 5. Modelfile ìƒì„±
    create_ollama_modelfile()
    
    print("\nğŸ‰ í•™ìŠµ ì™„ë£Œ!")
    print("\nğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:")
    print("1. Ollama ëª¨ë¸ ìƒì„±:")
    print("   ollama create travel-bot -f Modelfile")
    print("\n2. ëª¨ë¸ í…ŒìŠ¤íŠ¸:")
    print("   ollama run travel-bot")
    print("\n3. ì±—ë´‡ì—ì„œ ì‚¬ìš©:")
    print("   OLLAMA_MODEL=travel-bot í™˜ê²½ë³€ìˆ˜ ì„¤ì •")

if __name__ == "__main__":
    main() 